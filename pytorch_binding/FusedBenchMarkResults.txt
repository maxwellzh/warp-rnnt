warp-rnnt-compact
T=150	U=40	V=28	N=1	time=1.75   	memory=3
T=150	U=40	V=28	N=16	time=0.97   	memory=30
T=150	U=40	V=28	N=32	time=2.14   	memory=58
T=150	U=40	V=28	N=64	time=3.73   	memory=110
T=150	U=40	V=28	N=128	time=9.81   	memory=209

T=150	U=20	V=5000	N=1	time=3.24   	memory=243
T=150	U=20	V=5000	N=16	time=23.55  	memory=2768
T=150	U=20	V=5000	N=32	time=49.29  	memory=4993
T=150	U=20	V=5000	N=64	time=150.76 	memory=9671
T=150	U=20	V=5000	N=128	time=679.83 	memory=19286

T=1500	U=300	V=50	N=1	time=7.76   	memory=361
T=1500	U=300	V=50	N=16	time=59.95  	memory=3632
T=1500	U=300	V=50	N=32	time=140.36 	memory=6988
T=1500	U=300	V=50	N=64	time=411.21 	memory=14277
T=1500	U=300	V=50	N=128	error=CUDA out of memory. Tried to allocate 6.07 GiB (GPU 0; 23.70 GiB total capacity; 16.76 GiB already allocated; 5.78 GiB free; 16.85 GiB reserved in total by PyTorch)

T=400	U=100	V=1024	N=1	time=5.53   	memory=17997
T=400	U=100	V=1024	N=16	time=82.58  	memory=7165
T=400	U=100	V=1024	N=32	time=183.72 	memory=13580
T=400	U=100	V=1024	N=64	error=CUDA out of memory. Tried to allocate 5.72 GiB (GPU 0; 23.70 GiB total capacity; 17.16 GiB already allocated; 1.42 GiB free; 21.21 GiB reserved in total by PyTorch)


warp-rnnt-gather-compact
T=150	U=40	V=28	N=1	time=1.81   	memory=3
T=150	U=40	V=28	N=16	time=1.00   	memory=30
T=150	U=40	V=28	N=32	time=2.54   	memory=58
T=150	U=40	V=28	N=64	time=2.74   	memory=110
T=150	U=40	V=28	N=128	time=3.00   	memory=209

T=150	U=20	V=5000	N=1	time=3.09   	memory=243
T=150	U=20	V=5000	N=16	time=14.52  	memory=2768
T=150	U=20	V=5000	N=32	time=26.38  	memory=4993
T=150	U=20	V=5000	N=64	time=74.84  	memory=9671
T=150	U=20	V=5000	N=128	time=202.06 	memory=19286

T=1500	U=300	V=50	N=1	time=7.47   	memory=361
T=1500	U=300	V=50	N=16	time=34.40  	memory=3632
T=1500	U=300	V=50	N=32	time=91.33  	memory=6988
T=1500	U=300	V=50	N=64	time=149.41 	memory=14277
T=1500	U=300	V=50	N=128	error=CUDA out of memory. Tried to allocate 6.07 GiB (GPU 0; 23.70 GiB total capacity; 16.76 GiB already allocated; 5.78 GiB free; 16.85 GiB reserved in total by PyTorch)

T=400	U=100	V=1024	N=1	time=4.83   	memory=17997
T=400	U=100	V=1024	N=16	time=69.71  	memory=7165
T=400	U=100	V=1024	N=32	time=143.07 	memory=13580
T=400	U=100	V=1024	N=64	error=CUDA out of memory. Tried to allocate 5.72 GiB (GPU 0; 23.70 GiB total capacity; 17.16 GiB already allocated; 1.42 GiB free; 21.21 GiB reserved in total by PyTorch)


warp-rnnt-fused-compact
T=150	U=40	V=28	N=1	time=1.47   	memory=2
T=150	U=40	V=28	N=16	time=1.74   	memory=25
T=150	U=40	V=28	N=32	time=3.63   	memory=50
T=150	U=40	V=28	N=64	time=6.92   	memory=98
T=150	U=40	V=28	N=128	time=15.02  	memory=188

T=150	U=20	V=5000	N=1	time=3.28   	memory=182
T=150	U=20	V=5000	N=16	time=26.54  	memory=2244
T=150	U=20	V=5000	N=32	time=58.36  	memory=4284
T=150	U=20	V=5000	N=64	time=172.16 	memory=8464
T=150	U=20	V=5000	N=128	time=571.18 	memory=16469

T=1500	U=300	V=50	N=1	time=11.14  	memory=274
T=1500	U=300	V=50	N=16	time=108.64 	memory=3210
T=1500	U=300	V=50	N=32	time=240.81 	memory=6263
T=1500	U=300	V=50	N=64	time=634.18 	memory=12838
T=1500	U=300	V=50	N=128	error=CUDA out of memory. Tried to allocate 6.07 GiB (GPU 0; 23.70 GiB total capacity; 16.76 GiB already allocated; 5.78 GiB free; 16.85 GiB reserved in total by PyTorch)

T=400	U=100	V=1024	N=1	time=7.55   	memory=17997
T=400	U=100	V=1024	N=16	time=67.04  	memory=6061
T=400	U=100	V=1024	N=32	time=212.96 	memory=11885
T=400	U=100	V=1024	N=64	time=668.72 	memory=23412
T=400	U=100	V=1024	N=128	error=CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 23.70 GiB total capacity; 22.57 GiB already allocated; 36.56 MiB free; 22.60 GiB reserved in total by PyTorch)


